{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70eea3f",
   "metadata": {},
   "source": [
    "### Char-RNN(문자 단위) 사용해 셰익스피어 문체 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6709d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knuyh\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec90188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터셋 만들기\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e7d29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 글자 정수로 인코딩\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True) # 단어 수준 인코딩 대신 글자 수준 인코딩, 기본적으로 소문자로 변경\n",
    "tokenizer.fit_on_texts(shakespeare_text) # 빈도수 기준 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec8cf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"]) # F의 인덱스 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04dfbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb93cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # 고유한 문자 개수\n",
    "dataset_size = tokenizer.document_count # 전체 문자 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebe5f27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 1115394)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id, dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47ab087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 텍스트 인코딩\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
    "train_size = dataset_size * 90 // 100 # 처음 90%를 훈련셋으로 사용 ; 1003854\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "236d521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67cb29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nshift = 1 : 가장 큰 훈련 셋 생성\\ndrop_remainder = T\\n: 첫 번째 윈도 0 ~ 100\\n두 번째 윈도 1 ~ 101\\n패딩 없이 배치 데이터 만들기 위해 모든 윈도가 동일하게 101개의 글자 포함\\nif F일 경우, 윈도 100개는 글자 100개, 글자 99개 처럼 점점 줄어 마지막 윈도는 글자 1개\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 윈도 여러개로 자르기\n",
    "# TBPTT : window()로 긴 시퀀스를 작은 많은 텍스트 윈도로 변환하고, 부분 문자열 길이만큼만 역전파\n",
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = 1글자 앞의 input\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
    "'''\n",
    "shift = 1 : 가장 큰 훈련 셋 생성\n",
    "drop_remainder = T\n",
    ": 첫 번째 윈도 0 ~ 100\n",
    "두 번째 윈도 1 ~ 101\n",
    "패딩 없이 배치 데이터 만들기 위해 모든 윈도가 동일하게 101개의 글자 포함\n",
    "if F일 경우, 윈도 100개는 글자 100개, 글자 99개 처럼 점점 줄어 마지막 윈도는 글자 1개\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e02dd4",
   "metadata": {},
   "source": [
    "* 리스트의 리스트와 비슷한 중첩데이터셋 : 각 윈도를 변환할 때 유용,\n",
    "* 하지만 모델은 데이터셋이 아니라 텐서를 기대하기에 훈련에 중첩 데이터셋 바로 사용 X\n",
    "* 따라서 중첩 데이터셋을 플랫 데이터셋(데이터셋이 들어 있지 않는 데이터셋)으로 변환\n",
    "------------\n",
    "flat_map()  \n",
    "{{1, 2}, {3, 4, 5, 6}} -> [1, 2, 3, 4, 5, 6]  \n",
    "flat_map(lambda ds : ds.batch(2))  \n",
    "{{1, 2}, {3, 4}, {5, 6}} 텐서 2개를 가진 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37976d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window : window.batch(window_length))\n",
    "# 윈도마다 batch(window_length) 호출 : 윈도 길이와 같기에 텐서 하나를 담은 데이터셋\n",
    "# 연속된 101 글자 길이의 윈도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff8255e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8355f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 인코딩 (원핫벡터)\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d99fca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1faa6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 6131s 195ms/step - loss: 1.6196\n"
     ]
    }
   ],
   "source": [
    "# 모델 만들고 훈련하기\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     #dropout=0.2, recurrent_dropout=0.2), # 입력, 은닉상태\n",
    "                     dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=1) # epoch=10으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2808541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "def preprocess(texts) :\n",
    "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n",
    "    return tf.one_hot(X, max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfe2bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다음 글자 예측\n",
    "X_new = preprocess(['How are yo'])\n",
    "Y_pred = np.argmax(model(X_new), axis = -1)\n",
    "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫번째 문장, 마지막 글자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206daca",
   "metadata": {},
   "source": [
    "##### 가짜 셰익스피어 텍스트 생성하기\n",
    "* 예측한 다음 글자를 텍스트 끝에 추가하고, 늘어난 텍스트를 모델에 전달하여 다음 글자 예측하는 모델\n",
    "* 하지만, 같은 단어가 계속 반복되는 경우 많음\n",
    "* 대신 tf.random.categorical() 함수 사용해 모델이 추정한 확률을 기반으로 다음 글자 무작위 선택\n",
    "* 생성된 텍스트의 다양성 많이 제어하기 위해 temperature 숫자로 로짓 나눔\n",
    "    * 0에 가까울수록 높은 확률을 가진 글자 선택\n",
    "    * 높으면 모든 글자가 동일한 확률 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa284dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음글자 선택하고, 입력 텍스트에 추가\n",
    "def next_char(text, temperature=1):\n",
    "    X_new = preprocess([text])\n",
    "    y_proba = model(X_new)[0, -1:, :]\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0df578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char(\"How are yo\", temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7100d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_char 반복호출하여 다음 글자 얻고, 텍스트에 추가하는 함수\n",
    "def complete_text(text, n_chars=50, temperature=1) :\n",
    "    for _ in range(n_chars) :\n",
    "        text += next_char(text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "204eeca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "therefore i say,\n",
      "that i shall be your ben contrive \n",
      "trance it in slandle?\n",
      "\n",
      "gremio:\n",
      "o thas well deds arr\n",
      "to sesse! makt detpyers:\n",
      "so ha g! go you, ye, isere\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\", temperature=0.2))\n",
    "print(complete_text(\"t\", temperature=1))\n",
    "print(complete_text(\"t\", temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e87872",
   "metadata": {},
   "source": [
    "### 상태가 있는 RNN\n",
    "* 지금까지는 상태가 없는 RNN 사용\n",
    "* 훈련 반복마다 은닉 상태를 0으로 초기화\n",
    "* 타임 스텝마다 이 상태를 업데이트하고 마지막 타임 스텝 후에는 더 필요가 없기에 버림\n",
    "-------------\n",
    "* 상태가 있는 RNN : 훈련 배치를 처리한 후, 마지막 상태를 다음 훈련 배치의 초기 상태로 사용하여 역전파는 짧은 시퀀스에서 일어나지만, 모델이 장기간 패턴을 학습할 수 있다.\n",
    "* 배치에 있는 각 입력 시퀀스가 이전 배치의 시퀀스가 끝난 시점에서 시작해야 한다.\n",
    "* 연속적인 윈도가 같은 배치에 들어간다. 이 윈도가 끝난 지점부터 다음 배치가 계속되지 않는다.\n",
    "    * 첫 번째 배치 : 윈도 1 ~ 32\n",
    "    * 두 번째 배치 : 윈도 33 ~ 64\n",
    "    * 각 배치의 첫 번째 윈도를 생각하면 1, 33 연속적이지 않다.\n",
    "    * 해결 : 하나의 윈도를 갖는 배치를 만든다.\n",
    "------------------\n",
    "1. 순차적이고, 겹치지 않는 입력 시퀀스 만든다.\n",
    "2. window메서드에서 shift = n_steps 사용\n",
    "3. shuffle 메서드 호출해선 안된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37a2d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25e2f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00732dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True, # 각 순환층 만들 때 stateful=T\n",
    "                     #dropout=0.2, recurrent_dropout=0.2,\n",
    "                     dropout=0.2,\n",
    "                     batch_input_shape=[batch_size, None, max_id]), # 배치 크기 알아야 한다.(배치에 있는 입력 시퀀스 상태 보존해야하기 때문)\n",
    "    keras.layers.GRU(128, return_sequences=True, stateful=True,\n",
    "                     #dropout=0.2, recurrent_dropout=0.2),\n",
    "                     dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2045b1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch 끝마다 텍스트 다시 시작하기 전에 상태 재설정\n",
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b47327c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 45s 135ms/step - loss: 2.6223\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 2.2381\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 2.1071\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 48s 153ms/step - loss: 2.0317\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 1.9825\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 48s 152ms/step - loss: 1.9448\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 52s 165ms/step - loss: 1.9189\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 1.8965\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 51s 164ms/step - loss: 1.8770\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.8632\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 48s 153ms/step - loss: 1.8489\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 51s 161ms/step - loss: 1.8383\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.8283\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 51s 161ms/step - loss: 1.8179\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 48s 152ms/step - loss: 1.8109\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.8071\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 50s 160ms/step - loss: 1.7977\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 1.7936\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 52s 168ms/step - loss: 1.7883\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 48s 153ms/step - loss: 1.7819\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 58s 184ms/step - loss: 1.7793\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 48s 154ms/step - loss: 1.7731\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 53s 168ms/step - loss: 1.7697\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.7660\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 1.7624\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 1.7604\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 52s 165ms/step - loss: 1.7548\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 1.7536\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 51s 162ms/step - loss: 1.7518\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 47s 152ms/step - loss: 1.7476\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 1.7461\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 1.7434\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.7395\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 50s 161ms/step - loss: 1.7405\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 1.7361\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 1.7332\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 1.7341\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 48s 153ms/step - loss: 1.7313\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 1.7306\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 1.7267\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 47s 151ms/step - loss: 1.7237\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 1.7243\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 49s 157ms/step - loss: 1.7227\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 1.7213\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 49s 156ms/step - loss: 1.7205\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 1.7187\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 50s 159ms/step - loss: 1.7170\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 1.7154\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 51s 161ms/step - loss: 1.7160\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 1.7139\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])\n",
    "# 배치마다 샘플 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b6bf35",
   "metadata": {},
   "source": [
    "* 모델 훈련 후, 훈련할 때 사용한 것과 동일한 크기의 배치로만 예측 만들 수 있다.\n",
    "* 이런 제약 없애려면, 동일한 구조의 상태가 '없는' 모델 만들고, 상태가 있는 모델의 가중치 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4dd48a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateless_model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0af45b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 복사위해 먼저 모델 빌드\n",
    "stateless_model.build(tf.TensorShape([None, None, max_id]))\n",
    "\n",
    "stateless_model.set_weights(model.get_weights())\n",
    "model = stateless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0cebf2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tibre, forthing;\n",
      "isabel, she's i cantothat his sunt\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"t\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd28294",
   "metadata": {},
   "source": [
    "### 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e47be3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터셋 로드\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c23aaa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][:10] # 각 리뷰들의 리스트, 각 리뷰는 넘파이 정수 배열 : 각 정수는 하나의 단어, 빈도에 따라 인덱스(낮은 정수(0)=높은 빈도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4527cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1641221/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<sos> this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
    "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")): \n",
    "    # 정수 0 - 패딩, 1 - SOS(start of sequence), 2 - UNK\n",
    "    id_to_word[id_] = token\n",
    "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c1413633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\knuyh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a96937af624aa68e4d6e9cab7c0034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8913bcaf57c245d88b45c2bc56a0c686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\knuyh\\tensorflow_datasets\\imdb_reviews\\plain_text\\incomplete.ANYT9B_1.0.0\\imdb_reviews-trai…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\knuyh\\tensorflow_datasets\\imdb_reviews\\plain_text\\incomplete.ANYT9B_1.0.0\\imdb_reviews-test…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\knuyh\\tensorflow_datasets\\imdb_reviews\\plain_text\\incomplete.ANYT9B_1.0.0\\imdb_reviews-unsu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\knuyh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리를 모델 자체에 포함\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits['train'].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd9a893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e984c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300) # 각 리뷰에서 처음 300글자만 남김\n",
    "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch # default_value 지정하지 않으면 빈 바이트 문자열로 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ef4d165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 53), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Cons']], dtype=object)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0], dtype=int64)>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a50bff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘 사전 구축, 단어의 등장 횟수\n",
    "from collections import Counter\n",
    "\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in datasets['train'].batch(32).map(preprocess) :\n",
    "    for review in X_batch :\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38fb58f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f09f11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "def785bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 등장하는 단어 10000개만\n",
    "vocab_size = 10000\n",
    "truncated_vocabulary = [\n",
    "    word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c2f401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID(인덱스)로 바꾸는 전처리 단계\n",
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6cfc389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "12\n",
      "11\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
    "for word in b\"This movie was faaaaaantastic\".split():\n",
    "    print(word_to_id.get(word) or vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "95603988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]], dtype=int64)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "84c1adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = datasets[\"train\"].batch(32).map(preprocess) # 단어 -> 짧은 시퀀스\n",
    "train_set = train_set.map(encode_words).prefetch(1) # 단어 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d6c976c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 97s 114ms/step - loss: 0.5404 - accuracy: 0.7194\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 97s 124ms/step - loss: 0.3472 - accuracy: 0.8572\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 0.1921 - accuracy: 0.9324\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 0.1400 - accuracy: 0.9502\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 104s 133ms/step - loss: 0.1154 - accuracy: 0.9573\n"
     ]
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "                           mask_zero=True,\n",
    "                           input_shape=[None]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83b8b9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 104s 124ms/step - loss: 0.5398 - accuracy: 0.7155\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 100s 127ms/step - loss: 0.3474 - accuracy: 0.8560\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 98s 126ms/step - loss: 0.1855 - accuracy: 0.9347\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 96s 123ms/step - loss: 0.1356 - accuracy: 0.9521\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 99s 126ms/step - loss: 0.1051 - accuracy: 0.9615\n"
     ]
    }
   ],
   "source": [
    "# 마스킹\n",
    "# 패딩 토큰을 무시하도록 모델에게 알려주어 실제 의미가 있는 데이터에 집중할 수 있게\n",
    "# Embedding층에서 mask_zero = True -> 모든 층(IC=0)에서 패딩 토큰 무시\n",
    "K = keras.backend\n",
    "embed_size = 128\n",
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0b51522",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = '/tmp/tfhub_cache'\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "os.environ['TFHUB_CACHE_DIR'] = cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d7070000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 임베딩 재사용하기\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = keras.Sequential([\n",
    "    hub.KerasLayer(r\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]), # url에서 모듈(문장인코더) 다운로드\n",
    "    # 문자열을 입력으로 받아 50차원의 하나의 벡터로 인코딩\n",
    "    # hub.KerasLayer 층은 훈련되지 않음, trainable=True 설정하면 작업에 맞게 미세조정 가능\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "12ec829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a0a5d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.5489 - accuracy: 0.7235\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5142 - accuracy: 0.7487\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5089 - accuracy: 0.7510\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5052 - accuracy: 0.7550\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.5023 - accuracy: 0.7558\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n",
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755118b",
   "metadata": {},
   "source": [
    "### 신경망 기계 번역을 위한 인코더-디코더 네트워크\n",
    "* 자동 번역\n",
    "\n",
    "tensorflow_addons 설치 오류 이슈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c107d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embed_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa # 시퀀스 투 시퀀스 도구를 가지고 있음\n",
    "\n",
    "encoder_inputs = tensorflow.keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "encoder = keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler() # 각 스텝에서 디코더에게 이전 스텝의 출력이 무엇인지 알려줌\n",
    "# 훈련 시, 이전 타깃 토큰의 임베딩\n",
    "# 추론 시, 실제로 출력되는 토큰의 임베딩\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths)\n",
    "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
    "    outputs=[Y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7db1d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7db82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
    "seq_lengths = np.full([1000], 15)\n",
    "\n",
    "history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b882fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_24 (GRU)                (None, None, 10)          660       \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 20)          1320      \n",
      " al)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1980 (7.73 KB)\n",
      "Trainable params: 1980 (7.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 양방향 순환층\n",
    "# 층을 복사(반대방향으로), 그다음 두 층을 실행하여 그 출력 연결\n",
    "# ex. GRU 층이 10개 유닛을 가지면, 양방향 층은 타임 스텝마다 20개 값 출력\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(10, return_sequences=True, input_shape=[None, 10]),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6cf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빔 검색 : 모델이 앞선 실수를 고칠 수 있게 하는 방법\n",
    "# k(빔 너비)개의 가능성 있는 문장의 리스트 유지하고, 디코더 단계마다 이 문장의 단어를 하나씩 생성하여 가능성 있는 k개의 문장 만듦\n",
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
    "cell=decoder_cell, beam_width=beam_width, output_layer=output_layer)\n",
    "\n",
    "decoder_initial_state=tfa.seq2seq.beam_search_decoder.tile_batch(\n",
    "encoder_state, multiplier=beam_width) # 인코더의 마지막 상태 복사\n",
    "outputs, _, _ = decoder(embedding_decoder, start_tokens=start_tokens,\n",
    "                       end_token = end_token, initial_state=decoder_initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f049a1b",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "#### 인코더\n",
    "* 단어 ID의 시퀀스로 표현된 문장의 배치를 입력으로 받음 (입력 크기 : [배치크기, 입력 문장의 최대 길이])\n",
    "* 각 단어를 512차원의 표현으로 인코딩 (출력 크기 : [배치 크기, 입력 문장의 최대 길이, 512])\n",
    "\n",
    "    1) 인코더의 멀티-헤드 어텐션\n",
    "    * 관련이 많은 단어에 더 많은 주의를 기울이면서 각 단어와 동일한 문장에 있는 다른 단어와의 관계 인코딩\n",
    "     * ex) They welcomed the Queen of the United Kingdom -> Queen은 모든 단어에 의존적이지만, They나 welcomed 보다 United, Kingdom에 더 주의를 기울인다.\n",
    "     => **self- attention**\n",
    "#### 디코더\n",
    "* 훈련하는 동안 타깃 문장을 입력으로 받음\n",
    "    * 이 입력은 오른쪽으로 한 타임 스텝 이동되어 있음\n",
    "* 인코더의 출력을 받음\n",
    "* 디코더의 출력 크기 : [배치 크기, 출력 문장의 최대 길이, 어휘 사전 길이]\n",
    "* 추론 시에는 디코더에 타깃 주입할 수 없음\n",
    "\n",
    "    1) 디코더의 마스크드 멀티-헤드 어텐션\n",
    "    * 인코더의 멀티 헤드 어텐션과 동일한 작업 수행하지만, 각 단어는 이전에 등장한 단어에만 주의를 기울일 수 있다.\n",
    "    2) 디코더의 위쪽 멀티-헤드 어텐션 층\n",
    "    * 디코더가 입력 문장에 있는 단어에 주의를 기울이는 곳"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788beea",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "* 위치 인코딩 : 문장에 있는 단어의 위치를 나타내는 단순한 밀집 벡터\n",
    "    * 멀티-헤드 어텐션 층이 단어 사이 관계만 보고, 단어의 순서나 위치를 고려하지 않기에 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7fe1689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(keras.layers.Layer):\n",
    "    def __init__(self, max_steps, max_dims, dtype=tf.float32, **kwargs):\n",
    "        super().__init__(dtype=dtype, **kwargs)\n",
    "        if max_dims % 2 == 1: max_dims += 1 # max_dims 는 짝수여야\n",
    "        p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n",
    "        pos_emb = np.empty((1, max_steps, max_dims))\n",
    "        pos_emb[0, :, ::2] = np.sin(p / 10000**(2 * i / max_dims)).T\n",
    "        pos_emb[0, :, 1::2] = np.cos(p / 10000**(2 * i / max_dims)).T\n",
    "        self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n",
    "        \n",
    "    def call(self, inputs):  # 인코딩 행렬의 입력의 크기로 잘라 입력에 더함\n",
    "        shape = tf.shape(inputs)\n",
    "        return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eaffa946",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 201\n",
    "max_dims = 512\n",
    "pos_emb = PositionalEncoding(max_steps, max_dims)\n",
    "PE = pos_emb(np.zeros((1, max_steps, max_dims), np.float32))[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "75f49666",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 512; max_steps = 500; vocab_size = 10000\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "positional_encoding = PositionalEncoding(max_steps, max_dims=embed_size)\n",
    "encoder_in = positional_encoding(encoder_embeddings)\n",
    "decoder_in = positional_encoding(decoder_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1043ea5",
   "metadata": {},
   "source": [
    "* 멀티-헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6eac3cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n",
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n",
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n",
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n",
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n",
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n"
     ]
    }
   ],
   "source": [
    "Z = encoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, Z]) # use_scale : 파라미터 추가되어 유사도 점수의 스케일 적절히 낮추는 방법\n",
    "\n",
    "encoder_outputs = Z\n",
    "Z = decoder_in\n",
    "for N in range(6):\n",
    "    Z = keras.layers.Attention(use_scale=True, causal=True)([Z, Z]) # causal : 각 출력 토큰은 미래 토큰이 아닌 이전 출력 토큰에만 주의를 기울임\n",
    "    Z = keras.layers.Attention(use_scale=True)([Z, encoder_outputs])\n",
    "\n",
    "outputs = keras.layers.TimeDistributed(\n",
    "    keras.layers.Dense(vocab_size, activation=\"softmax\"))(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9ec36726",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class MultiHeadAttention(keras.layers.Layer):\n",
    "    def __init__(self, n_heads, causal=False, use_scale=False, **kwargs):\n",
    "        self.n_heads = n_heads\n",
    "        self.causal = causal\n",
    "        self.use_scale = use_scale\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.dims = batch_input_shape[0][-1]\n",
    "        self.q_dims, self.v_dims, self.k_dims = [self.dims // self.n_heads] * 3 # could be hyperparameters instead\n",
    "        self.q_linear = keras.layers.Conv1D(self.n_heads * self.q_dims, kernel_size=1, use_bias=False)\n",
    "        self.v_linear = keras.layers.Conv1D(self.n_heads * self.v_dims, kernel_size=1, use_bias=False)\n",
    "        self.k_linear = keras.layers.Conv1D(self.n_heads * self.k_dims, kernel_size=1, use_bias=False)\n",
    "        self.attention = keras.layers.Attention(causal=self.causal, use_scale=self.use_scale)\n",
    "        self.out_linear = keras.layers.Conv1D(self.dims, kernel_size=1, use_bias=False)\n",
    "        super().build(batch_input_shape)\n",
    "    def _multi_head_linear(self, inputs, linear):\n",
    "        shape = K.concatenate([K.shape(inputs)[:-1], [self.n_heads, -1]])\n",
    "        projected = K.reshape(linear(inputs), shape)\n",
    "        perm = K.permute_dimensions(projected, [0, 2, 1, 3])\n",
    "        return K.reshape(perm, [shape[0] * self.n_heads, shape[1], -1])\n",
    "    def call(self, inputs):\n",
    "        q = inputs[0]\n",
    "        v = inputs[1]\n",
    "        k = inputs[2] if len(inputs) > 2 else v\n",
    "        shape = K.shape(q)\n",
    "        q_proj = self._multi_head_linear(q, self.q_linear)\n",
    "        v_proj = self._multi_head_linear(v, self.v_linear)\n",
    "        k_proj = self._multi_head_linear(k, self.k_linear)\n",
    "        multi_attended = self.attention([q_proj, v_proj, k_proj])\n",
    "        shape_attended = K.shape(multi_attended)\n",
    "        reshaped_attended = K.reshape(multi_attended, [shape[0], self.n_heads, shape_attended[1], shape_attended[2]])\n",
    "        perm = K.permute_dimensions(reshaped_attended, [0, 2, 1, 3])\n",
    "        concat = K.reshape(perm, [shape[0], shape_attended[1], -1])\n",
    "        return self.out_linear(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e9f996f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`causal` argument is deprecated. Please use `use_causal_mask` in call() method to specify causal masking.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 50, 512])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = np.random.rand(2, 50, 512)\n",
    "V = np.random.rand(2, 80, 512)\n",
    "multi_attn = MultiHeadAttention(8)\n",
    "multi_attn([Q, V]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb2430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
